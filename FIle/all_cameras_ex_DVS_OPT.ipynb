{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbf8dd9-5311-42b0-b95b-11b8550d0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9d7574-b01a-4de0-8fda-aa604a08236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new client instance\n",
    "client = carla.Client('localhost', 2000)\n",
    "world = client.get_world()\n",
    "\n",
    "bp_lib = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "vehicle_bp = bp_lib.find('vehicle.dodge.charger')\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "\n",
    "spectator = world.get_spectator()\n",
    "transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-4, z=2.5)), vehicle.get_transform().rotation)\n",
    "spectator.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f1c804-9fcc-4321-b834-38b80f007271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the traffic light controller in the background\n",
    "traffic_light_process = subprocess.Popen(['python', 'traffic_light_controller.py'])\n",
    "traffic_process = subprocess.Popen(['python', 'generate_traffic.py', '--number-of-vehicles', '30', '--number-of-walkers', '50'])\n",
    "time.sleep(5)\n",
    "\n",
    "# Set up traffic manager\n",
    "traffic_manager = client.get_trafficmanager()\n",
    "vehicle.set_autopilot(True, traffic_manager.get_port())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8949758e-90f9-4aa6-ae80-a9d736b79646",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_init_trans = carla.Transform(carla.Location(x=0.0, y=0.0, z=1.6), carla.Rotation(pitch=0.0))\n",
    "\n",
    "def set_camera_attributes(camera_bp):\n",
    "    # Default settings for all cameras\n",
    "    camera_bp.set_attribute('image_size_x', '800')\n",
    "    camera_bp.set_attribute('image_size_y', '600')\n",
    "    camera_bp.set_attribute('fov', '90')\n",
    "\n",
    "# RGB camera\n",
    "camera_bp = bp_lib.find('sensor.camera.rgb')\n",
    "set_camera_attributes(camera_bp)\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "# Semantic camera\n",
    "sem_camera_bp = bp_lib.find('sensor.camera.semantic_segmentation')\n",
    "set_camera_attributes(sem_camera_bp)\n",
    "sem_camera = world.spawn_actor(sem_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "# Instance Segmentation camera\n",
    "inst_camera_bp = bp_lib.find('sensor.camera.instance_segmentation')\n",
    "set_camera_attributes(inst_camera_bp)\n",
    "inst_camera = world.spawn_actor(inst_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "# Monocular Depth camera\n",
    "depth_camera_bp = bp_lib.find('sensor.camera.depth')\n",
    "set_camera_attributes(depth_camera_bp)\n",
    "depth_camera = world.spawn_actor(depth_camera_bp, camera_init_trans, attach_to=vehicle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf838ca-94cb-4eda-9a02-e8c60f4e0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sensor data storage BEFORE calling `listen()`\n",
    "image_w = 800\n",
    "image_h = 600\n",
    "\n",
    "sensor_data = {\n",
    "    'rgb_image': np.zeros((image_h, image_w, 4), dtype=np.uint8),\n",
    "    'sem_image': np.zeros((image_h, image_w, 4), dtype=np.uint8),\n",
    "    'depth_image': np.zeros((image_h, image_w, 4), dtype=np.uint8),\n",
    "    'inst_image': np.zeros((image_h, image_w, 4), dtype=np.uint8),\n",
    "}\n",
    "\n",
    "def add_label(image, label, position=(10, 50), font_scale=0.8, color=(255, 255, 255)):\n",
    "    \"\"\"Adds a text label to an image.\"\"\"\n",
    "    labeled_image = image.copy()  # Work on a copy to avoid modifying original\n",
    "    cv2.putText(labeled_image, label, position, cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                font_scale, color, 2, cv2.LINE_AA)\n",
    "    return labeled_image  # Return the labeled image\n",
    "\n",
    "def rgb_callback(image, data_dict):\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    add_label(img, \"RGB Camera\")\n",
    "    data_dict['rgb_image'] = img\n",
    "\n",
    "def sem_callback(image, data_dict):\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    add_label(img, \"Semantic Segmentation\")\n",
    "    data_dict['sem_image'] = img\n",
    "\n",
    "def inst_callback(image, data_dict):\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    add_label(img, \"Instance Segmentation\")\n",
    "    data_dict['inst_image'] = img\n",
    "\n",
    "def depth_callback(image, data_dict):\n",
    "    image.convert(carla.ColorConverter.LogarithmicDepth)\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    add_label(img, \"Depth Camera\")\n",
    "    data_dict['depth_image'] = img\n",
    "\n",
    "# Start sensor listeners\n",
    "camera.listen(lambda image: rgb_callback(image, sensor_data))\n",
    "sem_camera.listen(lambda image: sem_callback(image, sensor_data))\n",
    "inst_camera.listen(lambda image: inst_callback(image, sensor_data))\n",
    "depth_camera.listen(lambda image: depth_callback(image, sensor_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e9f0fe-5362-4619-8a50-3b59d65006fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create display windows\n",
    "cv2.namedWindow('All Cameras', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('All Cameras', 1280, 960)\n",
    "\n",
    "cv2.namedWindow('Duplicate RGB', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Duplicate RGB', 800, 600)  # Keep RGB window smaller\n",
    "\n",
    "def preprocess_image(img):\n",
    "    \"\"\"Ensure all images have 3 channels (convert to RGB if needed).\"\"\"\n",
    "    if img.shape[2] == 4:  # If image has 4 channels (RGBA)\n",
    "        img = img[:, :, :3]  # Drop the alpha channel\n",
    "    return img\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Convert all sensor images to 3-channel RGB format\n",
    "        sensor_data_processed = {key: preprocess_image(img) for key, img in sensor_data.items()}\n",
    "\n",
    "        # Check if all images are available before displaying\n",
    "        if any(img.shape[0] == 0 for img in sensor_data_processed.values()):\n",
    "            print(\"Waiting for camera feeds...\")\n",
    "            continue\n",
    "\n",
    "        # Get the RGB image **without** label for the Duplicate RGB window\n",
    "        rgb_clean = sensor_data_processed['rgb_image'].copy()\n",
    "\n",
    "        # Create a **labeled** RGB image for the \"All Cameras\" window\n",
    "        rgb_labeled = add_label(sensor_data_processed['rgb_image'], \"RGB Camera\")\n",
    "\n",
    "        # Concatenate images in a 2-row format for display\n",
    "        top_row = np.concatenate([\n",
    "            rgb_labeled,  # Labeled RGB Image for \"All Cameras\"\n",
    "            add_label(sensor_data_processed['sem_image'], \"Semantic Segmentation\")\n",
    "        ], axis=1)\n",
    "        \n",
    "        lower_row = np.concatenate([\n",
    "            add_label(sensor_data_processed['depth_image'], \"Depth Camera\"),\n",
    "            add_label(sensor_data_processed['inst_image'], \"Instance Segmentation\")\n",
    "        ], axis=1)\n",
    "\n",
    "        # Combine both rows into a single tiled view\n",
    "        tiled = np.concatenate((top_row, lower_row), axis=0)\n",
    "\n",
    "        # Display the combined camera feeds in the main window\n",
    "        cv2.imshow('All Cameras', tiled)\n",
    "\n",
    "        # Display the clean RGB image in the Duplicate RGB window\n",
    "        cv2.imshow(\"Duplicate RGB\", rgb_clean)\n",
    "\n",
    "        # Exit on pressing 'q'\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"Error displaying images: {e}\")\n",
    "\n",
    "# Cleanup: Close all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e197426-a050-45f6-907d-dfdd732a7e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
